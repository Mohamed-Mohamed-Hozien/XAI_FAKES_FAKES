{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ------------------------\n# AE-CNN0 Architecture\n# ------------------------\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom PIL import Image\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nCLASS_NAMES = extract_labels\nCLASS_INDEX = {name: idx for idx, name in enumerate(CLASS_NAMES)}\n\nclass ChestXrayDataset(Dataset):\n    def __init__(self, csv_path, image_dir, transform=None, limit=None):\n        self.image_dir = image_dir\n        self.transform = transform\n        df = pd.read_csv(csv_path)\n        if limit:\n            df = df[:limit]\n        df['exists'] = df['Path'].apply(lambda x: os.path.exists(os.path.join(image_dir, str(x))))\n        df = df[df['exists']].drop(columns='exists')\n        label_counts = df[CLASS_NAMES].sum().sort_values(ascending=False)\n        print(\"\\U0001f50d Label counts in dataset:\")\n        print(label_counts[label_counts > 0])\n        self.image_paths = df['Path'].values\n        self.labels = df[CLASS_NAMES].values\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.image_dir, self.image_paths[idx])\n        img = Image.open(img_path).convert('L')\n        if self.transform:\n            img = self.transform(img)\n        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n        return img, label\n\nclass DenseNet121(nn.Module):\n    def __init__(self, classCount, isTrained):\n        super(DenseNet121, self).__init__()\n        self.densenet121 = models.densenet121(pretrained=isTrained)\n        kernelCount = self.densenet121.classifier.in_features\n        self.densenet121.classifier = nn.Sequential(\n            nn.Linear(kernelCount, classCount),\n            nn.Sigmoid()\n        )\n    def forward(self, x):\n        return self.densenet121(x)\n\nclass AECNN0(nn.Module):\n    def __init__(self, classCount):\n        super(AECNN0, self).__init__()\n        self.classCount = classCount\n        self.normalize = transforms.Normalize([0.485]*3, [0.229]*3)\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=5, stride=4, padding=2),\n            nn.ELU(),\n            nn.Conv2d(32, 1, kernel_size=1, stride=1, padding=0),\n        )\n        self.classifier = DenseNet121(classCount=self.classCount, isTrained=True)\n    def forward(self, x):\n        y = self.encoder(x)\n        y = y.clamp(min=0, max=1)\n        y3 = y.repeat(1, 3, 1, 1)\n        y3 = self.normalize(y3)\n        out = self.classifier(y3)\n        return y, out\n\ndef compute_auc(targets, outputs):\n    targets = np.array(targets)\n    outputs = np.array(outputs)\n    aucs = []\n    for i in range(targets.shape[1]):\n        try:\n            auc = roc_auc_score(targets[:, i], outputs[:, i])\n        except:\n            auc = np.nan\n        aucs.append(auc)\n    return aucs\n\ndef visualize_reconstruction(input_img, recon_img):\n    input_img = input_img.cpu().detach().numpy().squeeze()\n    recon_img = recon_img.cpu().detach().numpy().squeeze()\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n    axs[0].imshow(input_img, cmap='gray')\n    axs[0].set_title(\"Original\")\n    axs[1].imshow(recon_img, cmap='gray')\n    axs[1].set_title(\"Reconstructed\")\n    plt.show()\n\ndef plot_auc_bar(class_names, aucs):\n    plt.figure(figsize=(10,5))\n    sns.barplot(x=aucs, y=class_names)\n    plt.xlabel(\"AUC Score\")\n    plt.title(\"AUC per Class\")\n    plt.xlim(0, 1)\n    plt.grid(axis='x')\n    plt.show()\n\n# Setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncsv_path = \"labels.csv\"\nimage_dir = \"/kaggle/input/nih-balanced-and-resized-chest-x-rays/resized_images/resized_images\"\ntransform = transforms.Compose([\n    transforms.Resize((896, 896)),\n    transforms.ToTensor()\n])\ndataset = ChestXrayDataset(csv_path=csv_path, image_dir=image_dir, transform=transform, limit=1000)\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n\nmodel = AECNN0(classCount=len(CLASS_NAMES)).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ncriterion_bce = nn.BCELoss()\ncriterion_mse = nn.MSELoss()\n\n# Training\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    all_targets, all_outputs = [], []\n\n    for i, (images, targets) in enumerate(dataloader):\n        images, targets = images.to(device), targets.to(device)\n        recon, outputs = model(images)\n        images_resized = F.interpolate(images, size=(224, 224), mode='bilinear', align_corners=False)\n        loss_bce = criterion_bce(outputs, targets)\n        loss_mse = criterion_mse(recon, images_resized)\n        loss = 0.9 * loss_bce + 0.1 * loss_mse\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        all_targets.extend(targets.cpu().detach().numpy())\n        all_outputs.extend(outputs.cpu().detach().numpy())\n        if i == 0:\n            visualize_reconstruction(images[0], recon[0])\n\n    epoch_auc = compute_auc(all_targets, all_outputs)\n    print(f\"\\nEpoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")\n    print(\"AUC per class:\")\n    for name, auc in zip(CLASS_NAMES, epoch_auc):\n        print(f\"{name}: {auc:.4f}\")\n    print(f\"Average AUC: {np.nanmean(epoch_auc):.4f}\")\n\nplot_auc_bar(CLASS_NAMES, epoch_auc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\n\nmodel.eval()\n\n\nsample_indices = random.sample(range(len(dataset)), 50)\n\nfor idx in sample_indices:\n    img, true_label = dataset[idx]\n    with torch.no_grad():\n        img_input = img.unsqueeze(0).to(device)\n        _, pred = model(img_input)\n        pred = pred.cpu().squeeze().numpy()\n    \n    true_label = true_label.numpy()\n\n    # Get disease names\n    true_diseases = [CLASS_NAMES[i] for i, val in enumerate(true_label) if val == 1]\n    pred_diseases = [CLASS_NAMES[i] for i, val in enumerate(pred) if val >= 0.5]\n\n    plt.imshow(img.squeeze(), cmap='gray')\n    plt.axis('off')\n    plt.title(f\"True: {', '.join(true_diseases)}\\n  Predicted: {', '.join(pred_diseases)}\")\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Threshold 0.5\nbinary_preds = (np.array(all_outputs) >= 0.5).astype(int)\ntrue_labels = np.array(all_targets)\n\n# Compute average accuracy per label\nval_accuracy = (binary_preds == true_labels).mean()\nprint(f\" Validation Accuracy (overall): {val_accuracy:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.transforms.functional import normalize\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef generate_gradcam(model, input_tensor, target_class):\n    model.eval()\n    input_tensor = input_tensor.unsqueeze(0).to(device)\n\n    gradients, activations = [], []\n\n    def save_gradients_hook(module, grad_in, grad_out):\n        gradients.append(grad_out[0])\n\n    def save_activation_hook(module, input, output):\n        activations.append(output)\n\n    final_conv = model.classifier.densenet121.features[-1]\n    hook_a = final_conv.register_forward_hook(save_activation_hook)\n    hook_g = final_conv.register_backward_hook(save_gradients_hook)\n\n    output = model(input_tensor)[1]\n    class_score = output[0][target_class]\n    model.zero_grad()\n    class_score.backward()\n\n    grads = gradients[0].cpu().detach()\n    acts = activations[0].cpu().detach()\n    pooled_grads = grads.mean(dim=[0, 2, 3])\n    for i in range(acts.shape[1]):\n        acts[:, i, :, :] *= pooled_grads[i]\n\n    heatmap = acts.mean(dim=1).squeeze()\n    heatmap = np.maximum(heatmap, 0)\n    heatmap /= heatmap.max()\n\n    hook_a.remove()\n    hook_g.remove()\n    return heatmap.numpy()\n\n#Grad-CAM for N samples\nnum_samples = 4\nfor idx in range(num_samples):\n    img, label = dataset[idx]\n    input_tensor = img.unsqueeze(0).to(device)\n    output = model(input_tensor)[1]\n    probs = output.cpu().detach().numpy().squeeze()\n\n    pred_class = int(np.argmax(probs))\n    prob = probs[pred_class]\n    true_class = int(np.argmax(label.numpy()))  # get one active label\n\n    heatmap = generate_gradcam(model, img, target_class=pred_class)\n\n    plt.figure(figsize=(5, 5))\n    plt.imshow(img.squeeze(), cmap='gray')\n    plt.imshow(cv2.resize(heatmap, (896, 896)), cmap='jet', alpha=0.5)\n    plt.title(\n        f\"Pred: {CLASS_NAMES[pred_class]} ({prob:.2f})\\nTrue: {CLASS_NAMES[true_class]}\"\n    )\n    plt.axis('off')\n    plt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}